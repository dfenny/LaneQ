{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8afae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once, restart kernel and proceed with the next cell\n",
    "# %pip install --upgrade ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80eed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e20fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "\n",
    "import training\n",
    "from training import load_config, generate_basic_dataloader, generate_sppf_dataloader, get_model, train_loop, cal_regression_metrics\n",
    "from utils.preprocessing import load_image, apply_img_preprocessing\n",
    "\n",
    "from inference import load_saved_model, pred_degradation_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61a78ba",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68c5126",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./configs/cnn.yaml\"\n",
    "config = load_config(config_path)\n",
    "pprint(config,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87409566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy paste config here to edit and experiment\n",
    "config = {'dataset_loc': {'train': {'degradation_values_csv': './data/bdd100k/segments/degradation_segment_labels_train.csv',\n",
    "                           'img_dir': './data/bdd100k/segments/train/'},\n",
    "                 'val': {'degradation_values_csv': './data/bdd100k/segments/degradation_segment_labels_val.csv',\n",
    "                         'img_dir': './data/bdd100k/segments/val/'}},\n",
    "         'enable_cuda': True,\n",
    "         'model': {'in_channels': 3, 'out_dim': 1},\n",
    "         'results_loc': 'experiment_results/',\n",
    "         'training': {'batch_size': 1,\n",
    "                      'learning_rate': 0.05,\n",
    "                      'num_epochs': 10,\n",
    "                      'num_workers': 2,\n",
    "                      'resume_checkpoint': None,\n",
    "                      'save_checkpoint_freq': 1}\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2fc5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get required config parameters\n",
    "model_config = config[\"model\"]\n",
    "train_config = config[\"training\"]\n",
    "dataset_config = config[\"dataset_loc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c2b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"enable_cuda\"]:\n",
    "    training.DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using DEVICE: {training.DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804ecbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update preprocessing config if required\n",
    "# resize_height, resize_width = preprocess_config[\"resize_height\"], preprocess_config[\"resize_height\"]\n",
    "\n",
    "# # in case one wants to try out different transformations\n",
    "# img_transform = transforms.Compose([\n",
    "#     transforms.ToPILImage(),\n",
    "#     transforms.Resize((resize_height, resize_width)),   # ensure resize same is used for mask by setting preprocess_config\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "# generate train data loader\n",
    "train_loader, train_size = generate_sppf_dataloader(image_dir=dataset_config[\"train\"][\"img_dir\"],\n",
    "                                               degradation_values_csv=dataset_config[\"train\"][\"degradation_values_csv\"],\n",
    "                                               batch_size=train_config[\"batch_size\"],\n",
    "                                               num_workers=train_config[\"num_workers\"], transform=None,   # send new transform here if required\n",
    "                                               subset_size=1000)\n",
    "\n",
    "# generate validation data loader\n",
    "val_loader, val_size = generate_sppf_dataloader(image_dir=dataset_config[\"val\"][\"img_dir\"],\n",
    "                                                degradation_values_csv=dataset_config[\"val\"][\"degradation_values_csv\"],\n",
    "                                                batch_size=train_config[\"batch_size\"],\n",
    "                                                num_workers=train_config[\"num_workers\"], transform=None, \n",
    "                                                subset_size=500)\n",
    "\n",
    "print(f\"Train Dataset loaded. #samples: {train_size}\")\n",
    "print(f\"Validation Dataset loaded. #samples: {val_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201bbe70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ensure that we are getting correct data from data loaders\n",
    "batch_img, degradation_values = next(iter(train_loader))\n",
    "\n",
    "print(\"Image batch shape:\", batch_img.shape) \n",
    "# print(\"Degradation value:\", degradation_values.shape) \n",
    "\n",
    "sample_img = batch_img[0].numpy()   # (c, h, w)\n",
    "sample_img = sample_img.transpose(1, 2, 0)\n",
    "\n",
    "# sample_mask = batch_mask[0].numpy()   # (c, h, w)\n",
    "# sample_mask = np.squeeze(sample_mask) # (h, w)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.imshow(sample_img)\n",
    "ax.set_title(\"input image\")\n",
    "\n",
    "print(\"Degradation value:\", degradation_values[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5d932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model, loss function, and the optimizer\n",
    "model_name = \"cnn_sppf\"\n",
    "model = get_model(model_name, in_channels=model_config['in_channels'], out_dim=model_config['out_dim'])\n",
    "model = model.to(training.DEVICE)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=train_config[\"learning_rate\"])\n",
    "\n",
    "checkpoint_path = train_config[\"resume_checkpoint\"]\n",
    "if checkpoint_path is not None:\n",
    "    model.load_state_dict((torch.load(checkpoint_path, weights_only=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795ff510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchinfo import summary\n",
    "# summary(model, input_size=(1, 3, 4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2965e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "train_loop(model=model, loss_fn=criterion, optimizer=optimizer,\n",
    "           train_loader=train_loader, val_loader=val_loader,\n",
    "           num_epochs=train_config[\"num_epochs\"], save_path=config[\"results_loc\"],\n",
    "           checkpoint_freq=train_config[\"save_checkpoint_freq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0197a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open saved learning curve\n",
    "plot_saved_path = \"experiment_results/train_log/learning_curve_2025-03-15_00-08-40.png\"\n",
    "img = load_image(plot_saved_path)\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa6076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance at end of training using different losses\n",
    "train_losses = cal_regression_metrics(model, train_loader)\n",
    "val_losses = cal_regression_metrics(model, val_loader)\n",
    "\n",
    "print(f\"Train Loss: {train_losses}\")\n",
    "print(f\"Validation Loss: {val_losses}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e30b3b9",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2d6032",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_weight_path = \"experiment_results/checkpoints/cnn_sppf_final_2025-03-13_18-02-43.pth\"\n",
    "\n",
    "model_name = \"cnn_sppf\"\n",
    "model_config = {'in_channels': 3, 'out_dim': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252f2a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update preprocessing according to training\n",
    "resize_height, resize_width = 720, 1280\n",
    "\n",
    "# Define the image transformations\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((resize_height, resize_width)),   # ensure resize is same as used during training for loaded model \n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72755e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using DEVICE: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468ad395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize and load saved model\n",
    "model = load_saved_model(model_name=model_name, saved_weight_path=saved_weight_path, **model_config)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path = \"../damage_ratio_calc_data/segmented_objects/191_jpg.rf.e27c030e763e58ce48964e670158b6e7/191_jpg.rf.e27c030e763e58ce48964e670158b6e7_object_4.png\"\n",
    "test_img = load_image(test_img_path)\n",
    "print(\"Test image shape:\", test_img.shape)\n",
    "plt.imshow(test_img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Input image\", fontsize=9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8601b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = pred_degradation_value(model=model, test_img=test_img, img_transform=None, add_batch_dim=True, device=DEVICE)\n",
    "print(\"Predicticted degradation value:\", pred_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
