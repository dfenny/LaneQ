{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f6c53fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "\n",
    "# Additional code so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "from pprint import pprint\n",
    "from skimage.color import label2rgb\n",
    "from skimage.filters import threshold_otsu, threshold_li\n",
    "\n",
    "import degradation_utils as hp\n",
    "from calculate_degradation import fetch_all_components_degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace4e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f771ba97",
   "metadata": {},
   "source": [
    "# Inputs\n",
    "\n",
    "day\n",
    "- filename = \"b1d0091f-75824d0d.jpg\"  \n",
    "- filename = \"b1d4b62c-60aab822.jpg\"\n",
    "- filename = \"b5b02b31-f19988fb.jpg\"\n",
    "\n",
    "night\n",
    "- filename = \"b1ebfc3c-740ec84a.jpg\"\n",
    "- filename = \"b6bdb46e-3709d206.jpg\"\n",
    "- filename = \"b1d22449-117aa773.jpg\"\n",
    "\n",
    "other:\n",
    "- filename = \"0f68f127-05ff709b.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba2dcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path for image and mask\n",
    "img_dir = \"/cs6945share/retro_project/bdd100k/images/train/\"\n",
    "mask_dir = \"/cs6945share/retro_project/bdd100k/generated_masks_v0_3/masks_v3/train/\"\n",
    "\n",
    "segments_output_dir = \"./output/segments/\"\n",
    "annotations_output_dir = \"./output/annotations/\"\n",
    "\n",
    "# BEV output size \n",
    "bev_transform_shape = (640, 640)\n",
    "\n",
    "filename = \"00067cfb-f1b91e3c.jpg\"\n",
    "\n",
    "# filtering hyperparameters\n",
    "min_area = 100\n",
    "min_transform_area = 0.6\n",
    "min_segment_dimension = 4\n",
    "\n",
    "# degradation calculation hyperparameters\n",
    "component_len_limit = 100     # length of a lane above which degradatrion needs to be calculated in parts\n",
    "bin_length = 80               # length of a single part\n",
    "relax_threshold = 0.05        # percentage of the calculated threshold to reduce to relax the good pixel creterion \n",
    "\n",
    "# target class threshold bins\n",
    "degradation_threshold_bins = [0, 0.15, 0.3, 1]\n",
    "\n",
    "# class colors\n",
    "_color_map = {0: (0, 255, 0), 1: (255, 255, 0), 2: (255, 0, 0)}\n",
    "\n",
    "mask_name = \".\".join(filename.split(\".\")[:-1]) + \".png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91beb61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a1de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure all necessary folders are available\n",
    "os.makedirs(segments_output_dir, exist_ok=True)\n",
    "os.makedirs(annotations_output_dir, exist_ok=True)\n",
    "\n",
    "img_path = os.path.join(img_dir, filename)\n",
    "mask_path = os.path.join(mask_dir, mask_name)\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "mask_img = cv2.imread(mask_path)\n",
    "mask_img = cv2.cvtColor(mask_img, cv2.COLOR_BGR2GRAY)\n",
    "mask_img = mask_img / 255\n",
    "mask_img = mask_img.astype(np.uint8)\n",
    "\n",
    "# mask_img = np.zeros(mask_img.shape).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903a21ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize inputs\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(18, 10))\n",
    "\n",
    "ax[0].imshow(img)\n",
    "ax[0].axis(\"off\")\n",
    "ax[0].set_title(\"Original\")\n",
    "\n",
    "ax[1].imshow(mask_img, cmap=\"gray\")\n",
    "ax[1].axis(\"off\")\n",
    "ax[1].set_title(\"Mask\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plt.figure(figsize=(20,5))\n",
    "# plt.imshow(img)\n",
    "# plt.imshow(mask_img, alpha=0.2, cmap=\"Reds\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148af0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "add031ac",
   "metadata": {},
   "source": [
    "# Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d714f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate connected components\n",
    "num_labels, label_mask, bboxes = hp.generate_connected_components(mask_img, connectivity=8)\n",
    "\n",
    "# get ROI for transformation\n",
    "roi_points = hp.get_roi_points()\n",
    "\n",
    "# filtering of smaller components and components with less overlap with roi\n",
    "filtered_label_mask = hp.filter_connected_components(label_mask=label_mask, roi_points=roi_points, min_area=min_area, min_roi_overlap=min_transform_area)\n",
    "count = len(np.unique(filtered_label_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be076d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(18, 10))\n",
    "\n",
    "temp = np.zeros(label_mask.shape[:2])\n",
    "temp = cv2.fillPoly(temp, pts=[roi_points], color=1).astype(np.uint8)\n",
    "\n",
    "ax[0].imshow(label2rgb(label_mask))\n",
    "ax[0].imshow(temp, cmap=\"gray\", alpha=0.5)\n",
    "ax[0].axis(\"off\")\n",
    "ax[0].set_title(f\"Original connected components. Total - {num_labels}\")\n",
    "\n",
    "ax[1].imshow(label2rgb(filtered_label_mask))\n",
    "ax[1].axis(\"off\")\n",
    "ax[1].set_title(f\"Filtered components. Total - {count}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2daf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get transformation matrix\n",
    "matrix = hp.generate_perspective_matrix(roi_pts=roi_points, output_shape=bev_transform_shape)\n",
    "\n",
    "# Apply transformation on image\n",
    "img_bev = hp.apply_perspective_transform(img=img.copy(), matrix=matrix, output_shape=bev_transform_shape, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "# Apply transformation on labelled mask\n",
    "filtered_label_mask_bev = hp.apply_perspective_transform(img=filtered_label_mask.copy(), matrix=matrix, output_shape=bev_transform_shape, interpolation=cv2.INTER_NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9852b1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.array(roi_points, np.int32)\n",
    "d_points = points.reshape((-1, 1, 2))\n",
    "\n",
    "# visualize transformation\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 10))\n",
    "\n",
    "oimg = img.copy()\n",
    "oimg = cv2.polylines(oimg, [d_points], isClosed=True, color=(0, 255, 0), thickness=3)\n",
    "ax[0].imshow(oimg)\n",
    "ax[0].axis(\"off\")\n",
    "ax[0].set_title(\"Original\")\n",
    "\n",
    "ax[1].imshow(img_bev)\n",
    "ax[1].axis(\"off\")\n",
    "ax[1].set_title(\"BEV\")\n",
    "\n",
    "colored_label_mask = label2rgb(filtered_label_mask_bev, bg_label=0)\n",
    "ax[2].imshow(colored_label_mask)\n",
    "ax[2].axis(\"off\")\n",
    "ax[2].set_title(\"mask BEV\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072e79d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9976315",
   "metadata": {},
   "source": [
    "# Degradation Ratio Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38941ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting image to grayscale\n",
    "gray_img_bev = cv2.cvtColor(img_bev, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2646ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each component (skip label 0, which is the background)\n",
    "segment_labels = []\n",
    "annot_results = []\n",
    "\n",
    "component_degradation = fetch_all_components_degradation(gray_img=gray_img_bev, label_mask=filtered_label_mask_bev)\n",
    "\n",
    "save_name = \".\".join(filename.split(\".\")[:-1])  # remove extension\n",
    "\n",
    "# Loop over each component (skip label 0, which is the background)\n",
    "segment_labels = []\n",
    "annot_results = []\n",
    "for idx in range(1, num_labels):\n",
    "\n",
    "    degradation_ratio = component_degradation.get(idx, -1)   # get degradation ratio (-1 if not calculated)\n",
    "    coco_bbox = bboxes[idx].tolist()   # get bbox\n",
    "    \n",
    "    # if either dimension is less that required set ratio to -1\n",
    "    if coco_bbox[2] < min_segment_dimension or coco_bbox[3] < min_segment_dimension:\n",
    "        degradation_ratio = -1\n",
    "        \n",
    "    degradation_target = np.digitize(degradation_ratio, degradation_threshold_bins, right=True) - 1\n",
    "    degradation_target = int(degradation_target)  # required to save json\n",
    "\n",
    "    # save separate segment as png if degradation ratio is calculated\n",
    "    if degradation_ratio >= 0:\n",
    "        xmin, ymin, xmax, ymax = hp.box_coco_to_corner(coco_bbox)\n",
    "\n",
    "        # get segment in original image\n",
    "        orig_mask = (label_mask == idx).astype(np.uint8)\n",
    "        segment = cv2.bitwise_and(img, img, mask=orig_mask)         # apply mask\n",
    "        segment = segment[ymin:ymax + 1, xmin:xmax + 1].copy()      # get specific segment crop\n",
    "\n",
    "        # Write the segment to the output dir\n",
    "        segment_name = f\"{save_name}_{idx}.png\"\n",
    "        segment_path = os.path.join(segments_output_dir, segment_name)\n",
    "        cv2.imwrite(segment_path, cv2.cvtColor(segment, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        segment_info = {\n",
    "            \"name\": segment_name,\n",
    "            'degradation': degradation_ratio,\n",
    "            \"degradation_target\": degradation_target,\n",
    "            'ymax': ymax\n",
    "        }\n",
    "        segment_labels.append(segment_info)\n",
    "\n",
    "    # store annotations\n",
    "    mask_dict = {\n",
    "        'id': idx,\n",
    "        'bounding_box': coco_bbox,\n",
    "        'degradation': degradation_ratio,\n",
    "        \"degradation_target\": degradation_target\n",
    "    }\n",
    "    annot_results.append(mask_dict)\n",
    "    \n",
    "annotations_dict = {\n",
    "    'image': filename,\n",
    "    'annotations': annot_results\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a2a93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize results\n",
    "temp = img.copy()\n",
    "for component in annot_results:\n",
    "    ratio = component[\"degradation\"]\n",
    "    bbox = component[\"bounding_box\"]\n",
    "    target = component[\"degradation_target\"]\n",
    "    if ratio < 0:\n",
    "        continue\n",
    "    bbox = hp.box_coco_to_corner(bbox)\n",
    "    color = _color_map[target]\n",
    "    temp = hp.add_bbox(img=temp, bbox=bbox, label=f\"{round(ratio, 2)}\", font_scale=0.8, bbox_color=color)\n",
    "\n",
    "plt.imshow(temp)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9dee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment label csv\n",
    "segment_df = pd.DataFrame(segment_labels)\n",
    "segment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8757e454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image wise json\n",
    "json_out_path = os.path.join(annotations_output_dir, f\"{save_name}.json\")\n",
    "with open(json_out_path, 'w') as jspot:\n",
    "    json.dump(annotations_dict, jspot)\n",
    "\n",
    "annotations_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81035d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b34b7b6",
   "metadata": {},
   "source": [
    "## Single component degradation regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b6ff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "component_idx = 5\n",
    "component_idx = min(component_idx, num_labels)\n",
    "\n",
    "# Create a mask for the current object\n",
    "component_mask = (filtered_label_mask_bev == component_idx).astype(np.uint8)   \n",
    "\n",
    "# dilate the mask to include surrounding road region near lane marking for calculating threshold\n",
    "dilate_kernel = 13\n",
    "kernel = np.ones((dilate_kernel, dilate_kernel))\n",
    "dilated_mask = cv2.dilate(component_mask, kernel, iterations=1)\n",
    "\n",
    "# use this dialted region to get neighboring road color info\n",
    "road_plus_lane = cv2.bitwise_and(gray_img_bev, gray_img_bev, mask=dilated_mask)\n",
    "\n",
    "# crop given component from the grayscale image using mask\n",
    "component_region = cv2.bitwise_and(gray_img_bev, gray_img_bev, mask=component_mask)\n",
    "\n",
    "# placeholder to label each pixel as good or bad\n",
    "type_mask = component_mask.copy()\n",
    "\n",
    "# if lane is too long calculate degradation by dividing in horizontal bins\n",
    "non_zero_y, non_zero_x = np.nonzero(component_mask)\n",
    "ymin, ymax = non_zero_y.min() , non_zero_y.max() \n",
    "if (ymax - ymin) > component_len_limit: \n",
    "    # divide the component into horizontal bins\n",
    "    sub_comp_bins = np.arange(ymax, ymin, -bin_length)\n",
    "    if sub_comp_bins[-1] > ymin:\n",
    "        # if final bin doesnt cover the end of component add it\n",
    "        sub_comp_bins = np.append(sub_comp_bins, ymin)\n",
    "    \n",
    "    # each element is a compoent division y value as (ymax, ymin)\n",
    "    sub_comp_bins = list(zip(sub_comp_bins, sub_comp_bins[1:]))\n",
    "    \n",
    "else:\n",
    "    sub_comp_bins = [(ymax, ymin)]\n",
    "\n",
    "# do thresholding on each sub component separately:\n",
    "for sub_bin in sub_comp_bins:\n",
    "    \n",
    "    # crop sub component containing both road and lane\n",
    "    road_lane_crop = road_plus_lane[sub_bin[1]:sub_bin[0], :]\n",
    "    \n",
    "    # apply li thresholding to find threshold to separate lane color and road\n",
    "    good_threshold = threshold_li(road_lane_crop[road_lane_crop > 0])  # use only non-zero intensities\n",
    "    \n",
    "    if relax_threshold:\n",
    "        # relax the threshold further if required\n",
    "        good_threshold = good_threshold * (1 - relax_threshold)\n",
    "    \n",
    "    # find good intensity pixels\n",
    "    component_crop = component_region[sub_bin[1]:sub_bin[0], :]\n",
    "    undegraded_region = (component_crop >= good_threshold)\n",
    "    \n",
    "    # add the info to type mask\n",
    "    type_mask[sub_bin[1]:sub_bin[0], :][undegraded_region] = 2   \n",
    "    \n",
    "# calculate the total degradation \n",
    "total_area = np.sum(type_mask > 0)   # count of non zero pixels\n",
    "undegraded_area = np.sum(type_mask == 2)   # pixels marked as good (label:2)\n",
    "degradation_ratio = 1 - (undegraded_area / total_area)\n",
    "degradation_ratio = round(degradation_ratio, 4)\n",
    "\n",
    "print(\"Degradation Ratio:\", degradation_ratio)\n",
    "\n",
    "# visualize results\n",
    "colored_type_mask = label2rgb(type_mask, bg_label=0, colors=[\"red\", \"green\"])\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 10))\n",
    "ax[0].imshow(component_region, cmap=\"gray\")\n",
    "ax[0].axis(\"off\")\n",
    "ax[0].set_title(\"Cropped/filtered grayscale image using segmentation mask\")\n",
    "\n",
    "ax[1].imshow(colored_type_mask)\n",
    "ax[1].axis(\"off\")\n",
    "ax[1].set_title(\"Undegraded (green) and degreaded (red) pixels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968a6ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d49923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028572a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7a44487",
   "metadata": {},
   "source": [
    "### Script testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eb5162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calculate_degradation import main_degradation_annotations_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d175eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path for image and mask\n",
    "d_type = \"train\"\n",
    "img_dir = f\"/cs6945share/retro_project/bdd100k/images/{d_type}/\"\n",
    "mask_dir = f\"/cs6945share/retro_project/bdd100k/generated_masks_v0_3//masks_v3/{d_type}/\"\n",
    "\n",
    "segments_output_dir = f\"/cs6945share/retro_project/regression_bdd100k/segments/{d_type}/\"\n",
    "annotations_output_dir = f\"/cs6945share/retro_project/regression_bdd100k/annotations/{d_type}/\"\n",
    "\n",
    "# segments_output_dir = \"./output/segments/\"\n",
    "# annotations_output_dir = \"./output/annotations/\"\n",
    "\n",
    "bev_transform_shape = (640, 640)  # BEV output size \n",
    "\n",
    "# filtering hyperparameters\n",
    "min_area = 100\n",
    "min_transform_area = 0.6\n",
    "min_segment_dimension = 4\n",
    "\n",
    "# degradation calculation hyperparameters\n",
    "component_len_limit = 100     # length of a lane above which degradatrion needs to be calculated in parts\n",
    "bin_length = 80               # length of a single part\n",
    "relax_threshold = 0.05        # percentage of the calculated threshold to reduce to relax the good pixel creterion \n",
    "\n",
    "# target class threshold bins\n",
    "degradation_threshold_bins = [0, 0.1, 0.3, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6de0fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 17809/70000 [38:51<1:49:10,  7.97it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 56%|█████▌    | 38862/70000 [1:22:10<52:54,  9.81it/s]  IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 81%|████████  | 56571/70000 [1:58:22<38:26,  5.82it/s]"
     ]
    }
   ],
   "source": [
    "main_degradation_annotations_generator(image_dir=img_dir, mask_dir=mask_dir, segment_output_dir=segments_output_dir, annotations_output_dir=annotations_output_dir, \n",
    "                                       bev_shape=bev_transform_shape,\n",
    "                                       min_area=min_area, min_roi_overlap=min_transform_area, dilated_kernel=13, min_segment_dimension=min_segment_dimension,\n",
    "                                       comp_len_limit=component_len_limit, sub_comp_len=bin_length, relax_threshold=relax_threshold, degradation_bins=degradation_threshold_bins,\n",
    "                                       save_segments=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78270a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ../regression/data/bdd100k/segments/val/degradation_segment_labels.csv\n",
    "# ../regression/data/bdd100k/segments/val/degradation_segment_labels.csv\n",
    "# ../regression/data/bdd100k/segments/train/degradation_segment_labels.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61289c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mv /cs6945share/retro_project/regression_bdd100k/segments/val/degradation_segment_labels.csv /cs6945share/retro_project/regression_bdd100k/segments/val/degradation_segment_labels_val.csv\n",
    "# !mv /cs6945share/retro_project/regression_bdd100k/segments/val/degradation_segment_labels_val.csv /cs6945share/retro_project/regression_bdd100k/segments/degradation_segment_labels_val.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3c83e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mv /cs6945share/retro_project/regression_bdd100k/segments/train/degradation_segment_labels.csv /cs6945share/retro_project/regression_bdd100k/segments/train/degradation_segment_labels_train.csv\n",
    "# !mv /cs6945share/retro_project/regression_bdd100k/segments/train/degradation_segment_labels_train.csv /cs6945share/retro_project/regression_bdd100k/segments/degradation_segment_labels_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae306b61-18c0-429f-8ca9-907de4c965c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
