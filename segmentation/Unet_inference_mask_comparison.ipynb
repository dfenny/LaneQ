{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d67889ab-b8ce-4eb0-ab38-f90d4f7a7b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "\n",
    "import training\n",
    "from training import load_config, generate_dataloader, get_model, train_loop, cal_MeanIoU_score\n",
    "from utils.preprocessing import load_image, apply_img_preprocessing\n",
    "\n",
    "from inference import load_saved_model, pred_segmentation_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70897bf4-de7c-4973-aa4a-a06fd03487df",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_weight_path = \"experiment_results/checkpoints/unet_final_2025-03-23_14-17-47.pth\"\n",
    "\n",
    "model_name = \"unet\"\n",
    "model_config = {'in_channels': 3, 'out_channels': 1}\n",
    "inference_config = {'foreground_threshold': 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "611ebace-39e8-436d-bab2-942a07a7a23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update preprocessing according to training\n",
    "resize_height, resize_width = 360, 640\n",
    "\n",
    "# Define the image transformations\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((resize_height, resize_width)),   # ensure resize is same as used during training for loaded model \n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e202d6f-b776-4717-ba92-e83cb2a9c959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using DEVICE: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfd097cd-199b-4f68-a4ce-7f240baa7291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved weights loaded\n"
     ]
    }
   ],
   "source": [
    "# initialize and load saved model\n",
    "model = load_saved_model(model_name=model_name, saved_weight_path=saved_weight_path, **model_config)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81d9e791-43d6-41a2-a028-0e1b37b734dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"/cs6945share/retro_project/bdd100k/images/val/\"\n",
    "img_paths = glob(img_dir + \"*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee1695b2-6a41-49f3-8fbb-c4f45e6450a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c603f0deedab41f3808ae044269748f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='File:', index=30, layout=Layout(width='600px'), options=('â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def load_image(filename, max_width=800, max_height=800):\n",
    "    # Open image and preserve aspect ratio\n",
    "    img = Image.open(filename)\n",
    "    img.thumbnail((max_width, max_height))  # Resizes in-place with aspect ratio preserved\n",
    "\n",
    "    # Convert to bytes\n",
    "    with io.BytesIO() as output:\n",
    "        img.save(output, format='JPEG')\n",
    "        return output.getvalue()\n",
    "\n",
    "img_indice=30\n",
    "\n",
    "# Dropdown for file selection\n",
    "file_dropdown = widgets.Dropdown(\n",
    "    options=img_paths,\n",
    "    value=img_paths[img_indice],\n",
    "    description='File:',\n",
    "    layout=widgets.Layout(width='600px')  # Adjust width to suit your preference\n",
    ")\n",
    "\n",
    "# Two images side by side\n",
    "img_bytes = load_image(file_dropdown.value)\n",
    "\n",
    "left_image = widgets.Image(\n",
    "    # value=img_bytes,\n",
    "    format='jpg',\n",
    ")\n",
    "right_image = widgets.Image(\n",
    "    # value=img_bytes,\n",
    "    format='jpg',\n",
    ")\n",
    "\n",
    "def update_images(change=None):\n",
    "    selected_file = file_dropdown.value\n",
    "    img_bytes = load_image(selected_file)\n",
    "    left_image.value = img_bytes\n",
    "    right_image.value = img_bytes\n",
    "\n",
    "update_images()\n",
    "\n",
    "file_dropdown.observe(update_images, names=\"value\")\n",
    "\n",
    "# Navigation buttons\n",
    "prev_button = widgets.Button(description='Prev', button_style='')\n",
    "next_button = widgets.Button(description='Next', button_style='')\n",
    "\n",
    "def on_prev_clicked(b):\n",
    "    current_index = img_paths.index(file_dropdown.value)\n",
    "    new_index = (current_index - 1) % len(img_paths)  # wrap around\n",
    "    file_dropdown.value = img_paths[new_index]\n",
    "\n",
    "def on_next_clicked(b):\n",
    "    current_index = img_paths.index(file_dropdown.value)\n",
    "    new_index = (current_index + 1) % len(img_paths)  # wrap around\n",
    "    file_dropdown.value = img_paths[new_index]\n",
    "\n",
    "prev_button.on_click(on_prev_clicked)\n",
    "next_button.on_click(on_next_clicked)\n",
    "\n",
    "# Lay out the widgets\n",
    "# Top bar (file dropdown)\n",
    "top_bar = widgets.HBox([file_dropdown],\n",
    "                        layout=widgets.Layout(justify_content='center',margin='10px 0'))\n",
    "\n",
    "# Middle section (two images side by side)\n",
    "images_box = widgets.HBox([left_image, right_image],\n",
    "                          layout=widgets.Layout(justify_content='center'))\n",
    "\n",
    "# Bottom bar (prev and next buttons)\n",
    "bottom_bar = widgets.HBox([prev_button, next_button],\n",
    "                          layout=widgets.Layout(justify_content='center',margin='10px 0'))\n",
    "\n",
    "# Combine everything in a vertical box\n",
    "gui = widgets.VBox([top_bar, images_box, bottom_bar])\n",
    "\n",
    "display(gui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428e7585-2a51-46ba-b5a9-68a4a7297ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
